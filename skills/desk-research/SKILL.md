---
name: desk-research
description: 提案書の論点・仮説に基づくデスクトップリサーチを実行するスキル。WebSearch/WebFetch、Browser Use、Deep Researchプロンプト生成の3層で情報収集し、論点ごとに主張・根拠・ソースを整理した調査レポートと仮説検証シートを出力する。「デスクリサーチを実行して」「初期調査をして」「デスクトップ調査を行って」「追加調査をして」などのリクエスト時に使用。ワークフローのStep 3（初期デスクトップ調査）およびStep 10（デスクリサーチ）に対応。
---

# デスクリサーチ実行スキル

## 入出力

**入力**:

- 提案書（論点・仮説を含むファイル）のパス
- モード: `initial`（初期調査）または `detailed`（詳細調査）
- 出力先フォルダのパス

**追加入力**（detailedモードのみ）:

- インタビューまとめ（あれば）
- 既存の調査結果

**出力**:

- 調査レポート（Markdown）→ 指定された出力先フォルダ
- 仮説検証シート（レポート内に含む）

---

## モードの違い

| 項目 | initial | detailed |
|------|---------|----------|
| 対応ステップ | Step 3（初期デスクトップ調査） | Step 10（デスクリサーチ） |
| 調査範囲 | 提案書の全論点を網羅 | インタビュー等で判明したギャップに絞って深掘り |
| 仮説検証 | 初期仮説の初回検証 | 既に更新済みの仮説の再検証・補強 |
| 入力の違い | 提案書のみ | 提案書 + インタビューまとめ + 既存調査 |

---

## ワークフロー

### Step 1: 調査スコープの設計

`references/search-strategy.md` のセクション1を参照し、以下を実行する。

1. 提案書の論点（大論点・小論点）と仮説を一覧化
2. 各論点を具体的な調査項目に分解（「何が分かれば仮説を検証できるか」を定義）
3. 調査項目ごとに情報の種類（定量/定性/事例）を分類
4. 論点マトリクスを作成し、網羅性を確認
5. 優先順位を設定（高/中/低）

**detailedモードの場合**: 既存の調査結果・インタビューまとめを読み込み、情報が不足している箇所を特定してから調査項目を設計する。

**ユーザーへの確認**: スコープ設計の結果（論点マトリクス）をユーザーに提示し、追加・修正の要望がないか確認する。

### Step 2: 検索クエリの設計

`references/search-strategy.md` のセクション2を参照し、以下を実行する。

1. 各調査項目に対して最低5つの検索クエリを設計
2. 切り口を展開（類義語、上位/下位概念、業界固有用語、英語、ソース種類別）
3. 設計したクエリ一覧をメモとして保持（実行時の進捗管理用）

### Step 3: 情報収集の実行

3層の調査手段を段階的に使用する。

#### Layer 1: WebSearch / WebFetch

主軸の調査手段。以下の手順で実行する。

1. 優先度の高い調査項目から順に、設計したクエリでWebSearchを実行
2. 独立した調査項目のクエリは**並列にWebSearchを呼び出す**（効率化）
3. 検索結果から有望なURLを選定し、WebFetchで全文取得
4. 取得した情報を調査項目ごとに整理・記録
5. 各調査項目について、最低3つの異なるソースからの情報取得を目指す
6. 情報が不足する調査項目は、クエリを修正して再検索（最大3回）

**ソースの優先順位**:
- 公的統計・政府レポート > 業界団体 > 調査会社 > 上場企業IR > 専門メディア > 口コミ系

#### Layer 2: Browser Use

Layer 1 で不足がある場合に使用。以下のケースで活用する。

- ログインが必要なサイトでの情報収集
- 動的ページの操作（検索フィルタ、ソート、ページネーション等）
- データテーブルや一覧ページからの体系的な情報取得

**実行手順**:

1. Browser Use が必要な調査項目とサイトを特定
2. **ユーザーに確認**: 対象サイトのリストを提示し、ログイン状態の確保を依頼
3. ユーザーの承認後、Browser MCPまたはCursor IDE Browserで該当サイトにアクセス
4. 必要な情報を取得し、Markdown形式で記録

**注意事項**:
- ユーザーの明示的な承認なしにログインが必要なサイトへアクセスしない
- 取得したデータの出典URLとアクセス日時を記録する
- サイトの利用規約に反する大量スクレイピングは行わない

#### Layer 3: Deep Research プロンプト生成

Layer 1-2 でも情報が不足する場合の補完手段。

1. 不足している調査項目を特定し、ユーザーに報告
2. Perplexity / ChatGPT Deep Research 向けの最適化プロンプトを生成:

```
あなたは一流の経営コンサルタントでありリサーチのプロです。
以下の調査項目について、信頼性の高いソースに基づいた調査報告を作成してください。

## 調査項目

{不足している調査項目のリスト。各項目に「何を知りたいか」「なぜ必要か」を併記}

## 制約条件

### 調査方針
* 各項目に対して主張と根拠、ソースを記載してください
* 定量データを優先し、可能な限り数値で示してください
* できるだけ信頼性の高い情報を参考にしてください

### 出力時の留意点
* 適宜、表を使って整理してください
* 日本語で出力してください

## 既に判明していること（重複調査を避けるための参考）

{Layer 1-2 で取得済みの情報の要約}
```

3. プロンプトをユーザーに提示し、外部ツールでの実行を依頼
4. 結果がdocx形式の場合は `docx-to-markdown-with-references` スキルで変換
5. 結果を既存の調査結果と統合

### Step 4: 情報の統合・分析

1. 全Layer で収集した情報を論点ごとに集約
2. 各論点に対して「主張」「根拠」「ソース」を構成
3. ソースの信頼性を評価し、信頼性評価表を作成
4. 矛盾する情報がある場合は両論を併記し、判断の根拠を示す

### Step 5: 仮説検証・更新

提案書の初期仮説を一つずつ検証する。

1. 各仮説に対して、収集した情報を照合
2. 判定を行う:
   - **支持**: 裏付ける根拠が複数ソースから得られた → 補強した仮説文を提示
   - **否定**: 矛盾する情報が確認された → 修正した仮説文と理由を提示
   - **修正**: 部分的に正しいが精緻化が必要 → 修正箇所と根拠を明示
   - **未検証**: 十分な情報が得られなかった → 補完方法（インタビュー等）を提示
3. 仮説検証シートを作成

### Step 6: レポート作成

`references/output-format.md` に沿ってレポートを作成する。

- initialモード → initialモードのテンプレートを使用
- detailedモード → detailedモードのテンプレートを使用

### Step 7: 品質チェック

`references/quality-checklist.md` の全項目を確認し、不備があれば修正する。

---

## 品質ルール（常時適用）

- **三点セット必須**: 論点に対して主張・根拠・ソースを必ず揃える
- **ソース記録**: 情報源のURL/出典を逐一記録。口コミベースのデータには注記を付ける
- **捏造禁止**: 元のソースにない数字・固有名詞・事例を追加しない
- **曖昧さの保持**: 確認できなかった情報を推測で埋めない。不明点は不明のまま明記する
- **反証の探索**: 仮説を支持する情報だけでなく、否定する情報も積極的に収集する
- **鮮度の明示**: データの取得日・調査期間を明記する。古いデータには注記を付ける

---

## 参考資料

| ファイル | 内容 | 参照タイミング |
|---------|------|-------------|
| [references/search-strategy.md](references/search-strategy.md) | 調査スコープ設計・検索クエリ戦略 | Step 1-2 で参照 |
| [references/output-format.md](references/output-format.md) | 調査レポートのテンプレート | Step 6 で参照 |
| [references/quality-checklist.md](references/quality-checklist.md) | 品質チェックリスト | Step 7 で参照 |
